{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adhambarakat/supreme-chainsaw/blob/main/regressionXiot999.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Dependencies"
      ],
      "metadata": {
        "id": "ZqlsYAhOL4r_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjIEE5TCLkDS",
        "outputId": "97dc1c53-9117-4574-ac74-b760126caaca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting influxdb-client\n",
            "  Downloading influxdb_client-1.36.1-py3-none-any.whl (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.2/721.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting reactivex>=4.0.4 (from influxdb-client)\n",
            "  Downloading reactivex-4.0.4-py3-none-any.whl (217 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.8/217.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from influxdb-client) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from influxdb-client) (2.8.2)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from influxdb-client) (67.7.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from influxdb-client) (1.26.16)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->influxdb-client) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from reactivex>=4.0.4->influxdb-client) (4.7.1)\n",
            "Installing collected packages: reactivex, influxdb-client\n",
            "Successfully installed influxdb-client-1.36.1 reactivex-4.0.4\n",
            "Collecting flightsql-dbapi\n",
            "  Downloading flightsql_dbapi-0.2.1-py3-none-any.whl (23 kB)\n",
            "Collecting protobuf>=4.21.0 (from flightsql-dbapi)\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow>=10.0.0 (from flightsql-dbapi)\n",
            "  Downloading pyarrow-12.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.9/38.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlalchemy<2.0 (from flightsql-dbapi)\n",
            "  Downloading SQLAlchemy-1.4.49-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow>=10.0.0->flightsql-dbapi) (1.22.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2.0->flightsql-dbapi) (2.0.2)\n",
            "Installing collected packages: sqlalchemy, pyarrow, protobuf, flightsql-dbapi\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.18\n",
            "    Uninstalling SQLAlchemy-2.0.18:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.18\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 12.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flightsql-dbapi-0.2.1 protobuf-4.23.4 pyarrow-12.0.1 sqlalchemy-1.4.49\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Collecting paho-mqtt\n",
            "  Downloading paho-mqtt-1.6.1.tar.gz (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.4/99.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: paho-mqtt\n",
            "  Building wheel for paho-mqtt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paho-mqtt: filename=paho_mqtt-1.6.1-py3-none-any.whl size=62118 sha256=598aabf94d9d38071f76687688a3adbad79551070f6b12c90767f4d9007f98a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/bb/0c/79444d1dee20324d442856979b5b519b48828b0bd3d05df84a\n",
            "Successfully built paho-mqtt\n",
            "Installing collected packages: paho-mqtt\n",
            "Successfully installed paho-mqtt-1.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install influxdb-client\n",
        "!pip install flightsql-dbapi\n",
        "!pip install pandas\n",
        "!pip3 install paho-mqtt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "5g9SnN-yBu_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import influxdb_client, os, time\n",
        "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
        "from influxdb_client.client.write_api import SYNCHRONOUS\n",
        "import time\n",
        "import paho.mqtt.client as paho\n",
        "from paho import mqtt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.engine.training import optimizer\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.utils as to_categorica\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "metadata": {
        "id": "uAhxZRXMB1Tm"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Data"
      ],
      "metadata": {
        "id": "8rj30Ak0HBvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "GPdCuPhEHGcf",
        "outputId": "9568db5c-c9c1-4964-a192-ff576756b4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f323c7fe-4931-4097-bc00-c4065b013191\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f323c7fe-4931-4097-bc00-c4065b013191\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ppgsbpdbp.xlsx to ppgsbpdbp.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Allocating Data"
      ],
      "metadata": {
        "id": "CMKdnpogHJRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#allocating data\n",
        "data = pd.read_excel('/content/a7a6.xlsx')\n",
        "input_dim=1\n",
        "x_train = data['PPG']  #ptt training\n",
        "SBP = data['SBP']  #systolic\n",
        "DBP = data['DBP']  #diastolic\n",
        "y_train = np.column_stack((SBP,DBP))"
      ],
      "metadata": {
        "id": "cD7FlPofHMIn"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Model"
      ],
      "metadata": {
        "id": "Oi4_ingAHrrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu', input_shape=[input_dim]),\n",
        "    tf.keras.layers.Dense(units=2, input_shape=[input_dim])\n",
        "])"
      ],
      "metadata": {
        "id": "eaJeTyT9Hqi9"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the Model"
      ],
      "metadata": {
        "id": "QquXZ2zvIAnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['mae'])"
      ],
      "metadata": {
        "id": "b2u7weUdIA_v"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model"
      ],
      "metadata": {
        "id": "u_F_38QcIJIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(abs(x_train), y_train, epochs=250, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx8QtrdnIJaR",
        "outputId": "0696076c-4b88-4933-b1ec-ed83ad7da5bd"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "  7501/104858 [=>............................] - ETA: 2:52 - loss: 115.4121 - mae: 8.0160"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-165-01f2930490f6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\" - {now - self._start:.0f}s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connecting to Influxdb"
      ],
      "metadata": {
        "id": "mTGjLUzxB9DN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "P6QFOMwg5PiR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd8e6ae-2dd9-48fa-e8ac-14c5a2a14937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "123\n"
          ]
        }
      ],
      "source": [
        "# !export INFLUXDB_TOKEN=-g6iC2cK-mwZpYCPaiKdDOyyX5P1vkncIDSigkxs_ImaQJUDUm1-87FX4peKEmW4F2DC9CMSqZKVVTLNvXERSg==\n",
        "\n",
        "#token = os.environ.get(\"INFLUXDB_TOKEN\")\n",
        "token = \"-g6iC2cK-mwZpYCPaiKdDOyyX5P1vkncIDSigkxs_ImaQJUDUm1-87FX4peKEmW4F2DC9CMSqZKVVTLNvXERSg==\"\n",
        "org = \"test\"\n",
        "url = \"https://us-east-1-1.aws.cloud2.influxdata.com\"\n",
        "\n",
        "write_client = influxdb_client.InfluxDBClient(url=url, token=token, org=org)\n",
        "\n",
        "x = 123\n",
        "print (x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Receiving and Sending Data"
      ],
      "metadata": {
        "id": "ESvYqoRjIeG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting callbacks for different events to see if it works, print the message etc.\n",
        "def on_connect(client, userdata, flags, rc, properties=None):\n",
        "    print(\"CONNACK received with code %s.\" % rc)\n",
        "\n",
        "# with this callback you can see if your publish was successful\n",
        "def on_publish(client, userdata, mid, properties=None):\n",
        "    print(\"mid: \" + str(mid))\n",
        "\n",
        "# print which topic was subscribed to\n",
        "def on_subscribe(client, userdata, mid, granted_qos, properties=None):\n",
        "    print(\"Subscribed: \" + str(mid) + \" \" + str(granted_qos))\n",
        "\n",
        "# print message, useful for checking if it was successful\n",
        "def on_message(client, userdata, msg):\n",
        "    #print(msg.topic + \" \" + str(msg.qos) + \" \" + str(msg.payload))\n",
        "    #print(int(msg.payload))\n",
        "    if msg.topic == \"avgbpm\" :\n",
        "      bucket=\"colabtest\"\n",
        "      # Define the write api\n",
        "      write_api = write_client.write_api(write_options=SYNCHRONOUS)\n",
        "      data = {\n",
        "        \"point1\": {\n",
        "          \"location\": \"Hospital\",\n",
        "          \"dataa\": \"avghr\",\n",
        "          \"valuee\": int(msg.payload),\n",
        "        },\n",
        "      }\n",
        "      for key in data:\n",
        "        point = (\n",
        "          Point(\"avghr\")\n",
        "          .tag(\"location\", data[key][\"location\"])\n",
        "          .field(data[key][\"dataa\"], data[key][\"valuee\"])\n",
        "        )\n",
        "      write_api.write(bucket=bucket, org=org, record=point)\n",
        "      time.sleep(1) # separate points by 1 second\n",
        "      print(\"Complete. Return to the InfluxDB UI.\")\n",
        "      print(msg.payload)\n",
        "    elif msg.topic == \"ppg\" :\n",
        "      x_new=[[float(int(msg.payload)/100)]]\n",
        "      y_new = model.predict(np.array([[x_new]]))\n",
        "      a = y_new[0]\n",
        "      b = a[0]\n",
        "      c = b[0]\n",
        "      sbp = int(c[0])\n",
        "      dbp = int(c[1])\n",
        "      bucket=\"colabtest\"\n",
        "      # Define the write api\n",
        "      write_api = write_client.write_api(write_options=SYNCHRONOUS)\n",
        "      data = {\n",
        "        \"point2\": {\n",
        "          \"location\": \"Hospital\",\n",
        "          \"dataa\": \"sbp\",\n",
        "          \"valuee\": sbp,\n",
        "        },\n",
        "      }\n",
        "      for key in data:\n",
        "        point = (\n",
        "          Point(\"sp\")\n",
        "          .tag(\"location\", data[key][\"location\"])\n",
        "          .field(data[key][\"dataa\"], data[key][\"valuee\"])\n",
        "        )\n",
        "      write_api.write(bucket=bucket, org=org, record=point)\n",
        "      time.sleep(1) # separate points by 1 second\n",
        "      print(\"Complete. Return to the InfluxDB UI.\")\n",
        "      bucket=\"colabtest\"\n",
        "      # Define the write api\n",
        "      write_api = write_client.write_api(write_options=SYNCHRONOUS)\n",
        "      data = {\n",
        "        \"point3\": {\n",
        "          \"location\": \"Hospital\",\n",
        "          \"dataa\": \"dbp\",\n",
        "          \"valuee\": dbp+20,\n",
        "        },\n",
        "      }\n",
        "      for key in data:\n",
        "        point = (\n",
        "          Point(\"dp\")\n",
        "          .tag(\"location\", data[key][\"location\"])\n",
        "          .field(data[key][\"dataa\"], data[key][\"valuee\"])\n",
        "        )\n",
        "      write_api.write(bucket=bucket, org=org, record=point)\n",
        "      time.sleep(1) # separate points by 1 second\n",
        "      print(\"Complete. Return to the InfluxDB UI.\")\n",
        "      print(sbp)\n",
        "      print(dbp+20)\n",
        "    else :\n",
        "      bucket=\"colabtest\"\n",
        "      # Define the write api\n",
        "      write_api = write_client.write_api(write_options=SYNCHRONOUS)\n",
        "      data = {\n",
        "        \"point4\": {\n",
        "          \"location\": \"Hospital\",\n",
        "          \"dataa\": \"acchr\",\n",
        "          \"valuee\": int(msg.payload),\n",
        "        },\n",
        "      }\n",
        "      for key in data:\n",
        "        point = (\n",
        "          Point(\"acchr\")\n",
        "          .tag(\"location\", data[key][\"location\"])\n",
        "          .field(data[key][\"dataa\"], data[key][\"valuee\"])\n",
        "        )\n",
        "      write_api.write(bucket=bucket, org=org, record=point)\n",
        "      time.sleep(1) # separate points by 1 second\n",
        "      print(\"Complete. Return to the InfluxDB UI.\")\n",
        "      print(msg.payload)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    bucket=\"colabtest\"\n",
        "    # Define the write api\n",
        "    write_api = write_client.write_api(write_options=SYNCHRONOUS)\n",
        "    data = {\n",
        "      \"point4\": {\n",
        "        \"location\": \"Hospital\",\n",
        "        \"dataa\": \"hr\",\n",
        "        \"valuee\": int(msg.payload),\n",
        "      },\n",
        "    }\n",
        "    for key in data:\n",
        "      point = (\n",
        "        Point(\"bps\")\n",
        "        .tag(\"location\", data[key][\"location\"])\n",
        "        .field(data[key][\"dataa\"], data[key][\"valuee\"])\n",
        "      )\n",
        "    write_api.write(bucket=bucket, org=org, record=point)\n",
        "    time.sleep(1) # separate points by 1 second\n",
        "    print(\"Complete. Return to the InfluxDB UI.\")\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# using MQTT version 5 here, for 3.1.1: MQTTv311, 3.1: MQTTv31\n",
        "# userdata is user defined data of any type, updated by user_data_set()\n",
        "# client_id is the given name of the client\n",
        "client = paho.Client(client_id=\"\", userdata=None, protocol=paho.MQTTv5)\n",
        "client.on_connect = on_connect\n",
        "\n",
        "# enable TLS for secure connection\n",
        "client.tls_set(tls_version=mqtt.client.ssl.PROTOCOL_TLS)\n",
        "# set username and password\n",
        "client.username_pw_set(\"ahmed\", \"Ahmed1603\")\n",
        "# connect to HiveMQ Cloud on port 8883 (default for MQTT)\n",
        "client.connect(\"7ea331cfad864375a4a189652c9375e0.s1.eu.hivemq.cloud\", 8883)\n",
        "\n",
        "# setting callbacks, use separate functions like above for better visibility\n",
        "client.on_subscribe = on_subscribe\n",
        "client.on_message = on_message\n",
        "client.on_publish = on_publish\n",
        "\n",
        "# subscribe to all topics of encyclopedia by using the wildcard \"#\"\n",
        "client.subscribe(\"bpm\", qos=1)\n",
        "client.subscribe(\"ppg\", qos=1)\n",
        "client.subscribe(\"avgbpm\", qos=1)\n",
        "\n",
        "# a single publish, this can also be done in loops, etc.\n",
        "# client.publish(\"encyclopedia/temperature\", payload=\"hot\", qos=1)\n",
        "\n",
        "# loop_forever for simplicity, here you need to stop the loop manually\n",
        "# you can also use loop_start and loop_stop\n",
        "client.loop_forever()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZHKm9XNNvC2",
        "outputId": "6de647a9-0439-48e9-f93f-1d00e36960ff"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONNACK received with code Success.\n",
            "Subscribed: 1 [<paho.mqtt.reasoncodes.ReasonCodes object at 0x7f78318fc820>]\n",
            "Subscribed: 2 [<paho.mqtt.reasoncodes.ReasonCodes object at 0x7f78318fc910>]\n",
            "Subscribed: 3 [<paho.mqtt.reasoncodes.ReasonCodes object at 0x7f78318ffb20>]\n",
            "Complete. Return to the InfluxDB UI.\n",
            "b'2'\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "Complete. Return to the InfluxDB UI.\n",
            "Complete. Return to the InfluxDB UI.\n",
            "122\n",
            "70\n",
            "Complete. Return to the InfluxDB UI.\n",
            "b'35'\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Complete. Return to the InfluxDB UI.\n",
            "Complete. Return to the InfluxDB UI.\n",
            "124\n",
            "70\n",
            "Complete. Return to the InfluxDB UI.\n",
            "b'67'\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Complete. Return to the InfluxDB UI.\n",
            "Complete. Return to the InfluxDB UI.\n",
            "124\n",
            "70\n",
            "Complete. Return to the InfluxDB UI.\n",
            "b'67'\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Complete. Return to the InfluxDB UI.\n",
            "Complete. Return to the InfluxDB UI.\n",
            "125\n",
            "69\n",
            "Complete. Return to the InfluxDB UI.\n",
            "b'67'\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Complete. Return to the InfluxDB UI.\n",
            "Complete. Return to the InfluxDB UI.\n",
            "124\n",
            "70\n",
            "Complete. Return to the InfluxDB UI.\n",
            "b'62'\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Complete. Return to the InfluxDB UI.\n",
            "Complete. Return to the InfluxDB UI.\n",
            "121\n",
            "71\n",
            "Complete. Return to the InfluxDB UI.\n",
            "b'62'\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Complete. Return to the InfluxDB UI.\n",
            "Complete. Return to the InfluxDB UI.\n",
            "127\n",
            "68\n",
            "Complete. Return to the InfluxDB UI.\n",
            "b'67'\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Complete. Return to the InfluxDB UI.\n",
            "Complete. Return to the InfluxDB UI.\n",
            "124\n",
            "69\n",
            "Complete. Return to the InfluxDB UI.\n",
            "b'69'\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Complete. Return to the InfluxDB UI.\n",
            "Complete. Return to the InfluxDB UI.\n",
            "125\n",
            "69\n",
            "Complete. Return to the InfluxDB UI.\n",
            "b'69'\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Complete. Return to the InfluxDB UI.\n",
            "Complete. Return to the InfluxDB UI.\n",
            "123\n",
            "70\n",
            "Complete. Return to the InfluxDB UI.\n",
            "b'74'\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Complete. Return to the InfluxDB UI.\n",
            "Complete. Return to the InfluxDB UI.\n",
            "123\n",
            "70\n",
            "Complete. Return to the InfluxDB UI.\n",
            "b'69'\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Complete. Return to the InfluxDB UI.\n",
            "Complete. Return to the InfluxDB UI.\n",
            "124\n",
            "70\n",
            "Complete. Return to the InfluxDB UI.\n",
            "b'69'\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Complete. Return to the InfluxDB UI.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-1ecda3d51426>\u001b[0m in \u001b[0;36m<cell line: 161>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;31m# loop_forever for simplicity, here you need to stop the loop manually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;31m# you can also use loop_start and loop_stop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/paho/mqtt/client.py\u001b[0m in \u001b[0;36mloop_forever\u001b[0;34m(self, timeout, max_packets, retry_first_connection)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMQTT_ERR_SUCCESS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mrc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMQTT_ERR_SUCCESS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m                 \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m                 \u001b[0;31m# We don't need to worry about locking here, because we've\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                 \u001b[0;31m# either called loop_forever() when in single threaded mode, or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/paho/mqtt/client.py\u001b[0m in \u001b[0;36m_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocklist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpending_bytes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m             \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/paho/mqtt/client.py\u001b[0m in \u001b[0;36mloop_read\u001b[0;34m(self, max_packets)\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mMQTT_ERR_NO_CONN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1556\u001b[0;31m             \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_packet_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop_rc_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/paho/mqtt/client.py\u001b[0m in \u001b[0;36m_packet_read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2437\u001b[0m         \u001b[0;31m# All data for this packet is read.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_packet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2439\u001b[0;31m         \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_packet_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2441\u001b[0m         \u001b[0;31m# Free data and reset values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/paho/mqtt/client.py\u001b[0m in \u001b[0;36m_packet_handle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3031\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_pubackcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PUBCOMP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPUBLISH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3033\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3034\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPUBREC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_pubrec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/paho/mqtt/client.py\u001b[0m in \u001b[0;36m_handle_publish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3325\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3327\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_on_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3328\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mMQTT_ERR_SUCCESS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3329\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/paho/mqtt/client.py\u001b[0m in \u001b[0;36m_handle_on_message\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   3568\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_callback_mutex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3569\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3570\u001b[0;31m                     \u001b[0mon_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_userdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3571\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3572\u001b[0m                     self._easy_log(\n",
            "\u001b[0;32m<ipython-input-164-1ecda3d51426>\u001b[0m in \u001b[0;36mon_message\u001b[0;34m(client, userdata, msg)\u001b[0m\n\u001b[1;32m     80\u001b[0m         )\n\u001b[1;32m     81\u001b[0m       \u001b[0mwrite_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# separate points by 1 second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Complete. Return to the InfluxDB UI.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msbp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.array([[110],[77]])\n",
        "y_pred = np.array([[123],[70]])\n",
        "\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uzPZsgeRABi",
        "outputId": "04ef9913-84da-4841-ea2a-90a850ecc5ce"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 10.0000\n"
          ]
        }
      ]
    }
  ]
}